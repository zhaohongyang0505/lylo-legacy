# 定义

MQ（Message Queue，消息队列）是一种分布式系统中的异步通信机制。它通过消息的发送和接收，实现了不同系统或组件之间的解耦和异步通信。

# 作用

**异步:**
MQ 提供了异步通信能力，允许应用程序在发送消息后立即返回，无需等待消息处理完成。这种机制特别适用于高并发场景，如电商系统中订单支付后的积分计算、通知发送等后续操作，可以显著提升系统响应速度。

**解耦:**
MQ 作为中间件，有效降低了系统间的耦合度。生产者只需将消息发送到队列，无需关心消费者的具体实现。例如，支付系统完成交易后，通过
MQ 通知库存系统进行库存扣减，避免了系统间的直接依赖。

**削峰:**
MQ 具备流量缓冲能力，能够平滑处理突发流量，保护后端系统稳定性。在秒杀等高并发场景中，MQ 可以缓存大量请求，按照系统处理能力逐步消费，避免系统过载。
MQ 提供流量缓冲，平滑处理突发请求。在秒杀等高并发场景中，按系统处理能力逐步消费消息，保障系统稳定性。

# 常见的使用场景

**异步:**
在一些业务流程中，存在部分操作耗时较长且不影响主流程的立即响应。通过将这些耗时操作放入消息队列，主流程可以继续执行，而耗时操作会在后台异步处理，从而提高系统的整体响应速度和吞吐量。

**流量削峰:**
在业务高峰期，系统会收到大量的请求，若直接处理这些请求，可能导致系统负载过高甚至崩溃。消息队列可以作为缓冲，将大量请求先存入队列，系统再按照自身处理能力从队列中逐步获取请求进行处理，实现流量的削峰填谷，保护系统稳定性。

**日志处理:**
系统运行过程中会产生大量日志，如业务日志、操作日志等。将日志信息发送到消息队列，由专门的日志处理系统从队列中获取日志进行存储、分析和展示等操作，实现日志处理与业务系统的解耦，方便对日志进行统一管理。

**数据同步:**
在分布式系统中，不同数据库、不同系统之间需要进行数据同步。消息队列可作为数据同步的桥梁，当数据发生变化时，将变化的消息发送到消息队列，接收方从队列中获取消息并更新相应数据，实现数据的异步同步。

**任务调度:**
对于定时任务或按一定顺序执行的任务，可将任务信息放入消息队列，由任务调度系统从队列中获取任务并按规则调度执行，提高任务调度的灵活性和可扩展性。

**分布式事务(有遇到过吗):**
在分布式系统中，涉及多个服务之间的事务操作时，消息队列可用于实现最终一致性。通过将事务操作相关的消息发送到消息队列，各个服务根据消息进行相应操作，在一定时间内达到数据的一致性。

**广播通知:**
MQ可以将消息推送到多个订阅者，让不同的服务或者应用接收到通知。

# 常见的 MQ 中间件

| 特性 | Kafka | RabbitMQ | RocketMQ | ActiveMQ | Redis |
| --- | --- | --- | --- | --- | --- |
| **协议** | TCP | AMQP、STOMP、MQTT 等多种基于 TCP 的协议 | 自定义协议（基于 TCP） | OpenWire、STOMP、AMQP 等基于 TCP 的协议 | TCP |
| **开发语言** | Java、Scala | Erlang（服务端），多语言客户端 | Java | Java | C（多语言客户端） |
| **持久化** | 基于磁盘文件存储，利用顺序读写提升持久化性能，存储效率高 | 内存与磁盘均可持久化，存储策略灵活，可按需配置 | 采用内存映射文件实现高效磁盘存储，读写性能优异 | 支持内存、文件、数据库等多种持久化方式，适配不同场景 | 支持 RDB 和 AOF 方式持久化，但非主要用于消息队列 |
| **顺序消息** | 分区内有序，跨分区无序，适合局部顺序要求场景 | 通过单分区单消费者实现全局有序，配置相对简单 | 支持严格顺序消息队列，可保证消息顺序，满足强顺序需求 | 队列内有序，跨队列无序，可通过配置实现特定顺序，有一定灵活性 | 不支持 |
| **消息事务** | 0.11 版本后支持事务消息，实现机制有别于传统事务，需特定 API 操作 | 支持事务机制，通过事务标签确保收发一致性，操作方便 | 支持分布式事务消息，基于二阶段提交保障可靠性，适用于分布式场景 | 支持事务功能，运用 XA 事务等方式，遵循标准事务规范 | 不支持 |
| **吞吐量** | 极高，单机每秒可处理数万甚至数十万条，集群具备线性扩展能力，适合大数据量处理 | 较高，每秒能处理数千到数万条消息，性能较稳定 | 高，每秒处理数量介于 RabbitMQ 与 Kafka 之间，性能均衡 | 一般，高并发时单机每秒数千条左右，受资源限制明显，并发处理能力有限 | 较高，在简单消息队列操作方面表现良好，简单场景效率高 |
| **延迟** | 低延迟，尤其在大数据量高并发场景下表现突出，实时性好 | 低延迟，适用于对响应时间敏感的场景，响应迅速 | 低延迟，满足实时性要求高的业务，实时性保障强 | 延迟一般，高并发时延迟会增加，并发性能受影响 | 延迟较低，简单操作响应迅速，简单任务响应快 |
| **延迟消息** | 不直接支持，需借助额外手段模拟实现，实现复杂度高 | 借助插件（如 rabbitmq - delayed - message - exchange）实现，但长时间延迟会损耗性能，长时间延迟有局限 | 支持设置延迟级别，高效处理不同延迟需求，但不够灵活，级别设置固定 | 支持设置消息属性实现，但高并发下延迟处理稳定性欠佳，高并发表现弱 | 不支持，可通过 Lua 脚本结合特定数据结构模拟，复杂场景实现困难且性能一般，复杂场景不适用 |
| **消息重试** | 消费者端需自行编写重试逻辑，开发成本高 | 支持，可通过死信队列等机制实现，机制成熟 | 支持多种重试策略，可依据业务定制，策略丰富 | 支持，通过配置重试参数操作简便，配置简单 | 不支持 |
| **消息消费方式** | 拉取式，消费者自主控制消费节奏，自主性强 | 支持推送式（可配置为拉取式），可按需选择，灵活性高 | 支持推送与拉取两种方式，使用灵活，选择多样 | 支持推送式（可配置为拉取式），配置灵活，可灵活配置 | 类似拉取（客户端主动获取），基于订阅/发布，简单直接 |
| **优点** | 高吞吐量、低延迟、分区有序、高可用，适合大数据流处理，大数据处理优势明显 | 高可靠、多协议支持、配置灵活、社区丰富，应用场景广泛，适用性强 | 高性能、支持分布式事务、严格保证消息顺序，适用于金融等高要求场景，金融场景适配好 | 功能全面、历史悠久、易于集成，能满足多种业务需求，集成方便 | 简单易用、高性能、数据结构丰富，可用于多种场景，使用便捷 |
| **缺点** | 跨分区无序、事务复杂、运维难度大，对运维人员要求高，运维成本高 | Erlang 语言门槛、配置繁琐、高吞吐量性能相对较弱，部署成本高，开发部署难度大 | 社区活跃度较低、生态不够丰富、部署运维困难，技术支持有限，社区支持不足 | 高并发大数据量下性能受限，资源利用效率有待提高，高并发性能差 | 内存有限、不适用于大量消息持久化、复杂消息处理能力差，不适合大规模消息队列，大规模应用受限 |
| **消费者 ack** | 消费者通过管理偏移量确认消息消费，可精准控制消费进度，失败时可依据偏移量重设消费位置，消费控制精准 | 自动确认（可手动配置为手动确认），手动确认需消费者显式调用确认方法，确认方式灵活 | 内置确认机制，支持批量确认以提高效率，确认效率高 | 自动确认（可手动配置为手动确认），配置灵活，可按需配置 | 不支持明确的消费者 ack 机制，通过客户端接收消息隐式确认，确认机制不明确 |
| **生产者 ack** | 生产者可配置要求 Broker 返回确认信息：acks = 0 无需等待 Broker 响应；acks = 1 消息需写入 leader 副本；acks = -1 或 acks = all 消息需写入所有 isr 副本，确认配置灵活 | 生产者可设置消息确认模式，如 publisher confirms 机制等待 Broker 确认消息接收，确认模式多样 | 生产者发送消息后，RocketMQ 会返回发送结果，包括成功、失败及失败原因，结果反馈详细 | 生产者发送消息后可获取发送结果，不同持久化方式和事务配置影响确认机制，确认受配置影响 | 生产者通过 Redis 命令执行结果判断消息是否成功入队，缺乏专业 MQ 的复杂确认机制，可靠性保障有限，确认机制简单 |
| **适用场景** | 大数据领域，如日志收集、实时数据处理等高吞吐量场景，大数据场景首选 | 对可靠性、低延迟要求高的场景，如金融、实时通信，金融通信适用 | 对数据可靠性、实时性要求高且需处理大量队列的场景，如金融交易，金融交易适配 | 多种消息队列场景，功能全面但高吞吐量性能较弱，通用场景合适 | 简单消息队列场景，如缓存失效通知，简单场景适用 | 

# Kafka

## 核心概念
**Topic:**
Topic 是消息的分类单位，生产者将消息发送到指定的 Topic，消费者从 Topic 订阅消息。

**Partition:**
是Kafka下数据存储的基本单元，这个是物理上的概念。一个 topic 可以分为多个 partition，每个 partition 都是一个有序的队列，同一个分区（partition）可以被不同的消费者组同时消费，但是同一个消费者组内只能被一个消费者消费，通过提升分区数量可以提升同一个Topic的吞吐量

**Broker:**
一台 kafka 服务器就是一个 broker。一个kafka集群由多个 broker 组成。

**Producer:**
Producer 是消息的生产者，负责将消息发送到指定的 Topic。

**Consumer:**
Consumer 是消息的消费者，负责从指定的 Topic 订阅消息并处理。

**Consumer Group:**
Consumer Group 是一组消费者，每个 Consumer Group 可以消费同一个 Topic 的不同 Partition。

**Offset:**
Offset 是消息在 Partition 中的唯一标识符，用于标识消息的位置。

**Leader:**
Leader 是 Partition 的主节点，负责处理消息的读写操作。

**Follower:**
Follower 是 Partition 的从节点，复制 Leader 的消息，保持与 Leader 的同步。

**ISR:**
Kafka中通常每个分区都有多个副本，其中一个副本被选举为 Leader，其他副本为 Follower。ISR 是指与 Leader 副本保持同步的 Follower 副本集合。ISR 机制的核心是确保数据在多个副本之间的一致性和可靠性，同时在 Leader 副本出现故障时能够快速进行故障转移，保证服务的可用性。


# 常见面试题
## 消息积压
**原因:**
1. 消息生产速度过快，导致消费者无法及时处理，消息堆积在队列中。
2. 消费者处理能力不足，无法及时处理堆积的消息，导致消息堆积。
3. 分区分配不合理。
4. 网络或者硬件瓶颈。

**解决方法:**
1. 增加消费者数量，提高消费者处理能力。
2. 优化消费者消费逻辑，减少消息处理时间。
3. 合理分配分区，避免分区分配不合理导致消息堆积。
4. 优化网络或者硬件配置，提高消息处理速度。

## 消息丢失
**原因:**
1. 生产者发送消息时，acks为0，消息未到达broker。
2. 生产者发送消息时，acks为1，leader还未将数据同步到其他follower就宕机了。
3. leader与follower的消息都还未落盘就宕机了。
4. 消费者消费消息时，提前提交了偏移量，但是消息未最终处理。

**解决方法:**
1. 将acks设置all，降低生产者丢失消息的概率。
2. 消费者手动提交偏移量，确保消息最终处理。

## 重复消费
**原因:**
1. 生产者重复提交消息，例如重试等等。
2. 消费者处理了消息，但是为提交偏移量。

**解决方法:**
1. 消费者消费消息时使用幂等操作。
2. 消息添加唯一标识，消费者消费消息时，对标识做过滤判断，避免重复消费。


# 什么是消息队列？
- 一种对数据进行流处理的解决方案，实现不一定靠队列（比如日志），也叫消息中间件、消息代理
# 数据密集型应用的三种数据处理方式
- 服务（在线处理）
- 批处理（离线处理）
- 流处理（准实时）
# 什么情况下需要进行流处理？
- 解耦系统组件：生产者和消费者可以不需要知道彼此存在，只需与队列交互
- 异步处理：生产者不需要等待消费者处理完成，消费者可以异步处理
- 削峰填谷：平滑处理请求高峰，避免系统过载
# 举例
- 生产者：订单支付成功
- 消费者：发放优惠券
